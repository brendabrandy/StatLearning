{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to demonstrate how to implement logistic regression with stochastic gradient descent. \n",
    "\n",
    "In this project, we are trying to do gender voice recognition with logistic regression. The data is obtained from kaggle, where each voice signal has already been analyzed and the data about the voice samples are recorded numerically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare notebook and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import *\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data and see what is in there (first ten lines)\n",
    "\n",
    "df_voice=pd.read_csv(\"voice.csv\")\n",
    "df_voice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the dataframe itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the variables are represented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meanfreq',\n",
       " 'sd',\n",
       " 'median',\n",
       " 'Q25',\n",
       " 'Q75',\n",
       " 'IQR',\n",
       " 'skew',\n",
       " 'kurt',\n",
       " 'sp.ent',\n",
       " 'sfm',\n",
       " 'mode',\n",
       " 'centroid',\n",
       " 'meanfun',\n",
       " 'minfun',\n",
       " 'maxfun',\n",
       " 'meandom',\n",
       " 'mindom',\n",
       " 'maxdom',\n",
       " 'dfrange',\n",
       " 'modindx',\n",
       " 'label']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_voice.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since label is now a categorical data, split into males and females, it would be beneficial to convert them to 0 and 1, where 0 represent females and 1 represent males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_dict = {\"male\":1.0, \"female\":0.0}\n",
    "df_voice[\"gender\"] = df_voice[\"label\"].map(gender_dict);\n",
    "df_voice = df_voice.drop(\"label\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm   ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918   ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724   ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905   ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232   ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568   ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  gender  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000     1.0  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632     1.0  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512     1.0  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119     1.0  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274     1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data that we have, and from the data, we observe several problems:\n",
    "\n",
    "1. The data is listed in such a way that the male voices comes first and female voices comes later, therefore we need to shuffle the rows to ensure that both male and female voices are taken into account of the learning process.\n",
    "2. Males and females are label, and we need to change them into 0 and 1 so that we can fit the data into the logistic regression algorithm\n",
    "3. We need a set of testing data to test the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_voice = (df_voice - df_voice.mean()) / (df_voice.max() - df_voice.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_num_dict = {0.5:1.0, -0.5:0.0}\n",
    "df_voice[\"gender\"] = df_voice[\"gender\"].map(gender_num_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_voice = df_voice.iloc[np.random.permutation(len(df_voice))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.100945</td>\n",
       "      <td>0.187258</td>\n",
       "      <td>-0.154915</td>\n",
       "      <td>-0.077117</td>\n",
       "      <td>0.063359</td>\n",
       "      <td>0.141638</td>\n",
       "      <td>-0.033156</td>\n",
       "      <td>-0.022713</td>\n",
       "      <td>0.106866</td>\n",
       "      <td>0.216255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100945</td>\n",
       "      <td>-0.123865</td>\n",
       "      <td>-0.094643</td>\n",
       "      <td>-0.513695</td>\n",
       "      <td>-0.154699</td>\n",
       "      <td>-0.098732</td>\n",
       "      <td>-0.111527</td>\n",
       "      <td>-0.109554</td>\n",
       "      <td>0.046189</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>-0.077168</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>-0.062242</td>\n",
       "      <td>-0.088110</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>-0.054276</td>\n",
       "      <td>-0.024488</td>\n",
       "      <td>0.271365</td>\n",
       "      <td>0.362597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077168</td>\n",
       "      <td>-0.129024</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>-0.215011</td>\n",
       "      <td>-0.098732</td>\n",
       "      <td>-0.199089</td>\n",
       "      <td>-0.197179</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>0.075031</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.104885</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.102318</td>\n",
       "      <td>0.078041</td>\n",
       "      <td>-0.056251</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>0.044442</td>\n",
       "      <td>-0.103720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075031</td>\n",
       "      <td>-0.071623</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.114915</td>\n",
       "      <td>-0.059927</td>\n",
       "      <td>-0.064324</td>\n",
       "      <td>-0.019675</td>\n",
       "      <td>-0.018352</td>\n",
       "      <td>-0.076912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>0.181834</td>\n",
       "      <td>-0.201178</td>\n",
       "      <td>0.151694</td>\n",
       "      <td>0.272120</td>\n",
       "      <td>0.052881</td>\n",
       "      <td>-0.231650</td>\n",
       "      <td>-0.014459</td>\n",
       "      <td>-0.019957</td>\n",
       "      <td>-0.217464</td>\n",
       "      <td>-0.210421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181834</td>\n",
       "      <td>0.045072</td>\n",
       "      <td>0.053981</td>\n",
       "      <td>0.105751</td>\n",
       "      <td>0.581402</td>\n",
       "      <td>-0.064324</td>\n",
       "      <td>0.292333</td>\n",
       "      <td>0.293880</td>\n",
       "      <td>-0.032648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-0.010806</td>\n",
       "      <td>0.162614</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>-0.059089</td>\n",
       "      <td>0.066089</td>\n",
       "      <td>0.125541</td>\n",
       "      <td>-0.042234</td>\n",
       "      <td>-0.023494</td>\n",
       "      <td>0.186387</td>\n",
       "      <td>0.240967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010806</td>\n",
       "      <td>-0.173962</td>\n",
       "      <td>-0.106809</td>\n",
       "      <td>-0.561536</td>\n",
       "      <td>0.052686</td>\n",
       "      <td>-0.047120</td>\n",
       "      <td>0.074678</td>\n",
       "      <td>0.075711</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "35   -0.100945  0.187258 -0.154915 -0.077117  0.063359  0.141638 -0.033156   \n",
       "627  -0.077168  0.098706 -0.062242 -0.088110 -0.018893  0.073288 -0.054276   \n",
       "1375  0.075031  0.006741  0.104885  0.020391  0.102318  0.078041 -0.056251   \n",
       "2425  0.181834 -0.201178  0.151694  0.272120  0.052881 -0.231650 -0.014459   \n",
       "446  -0.010806  0.162614  0.079876 -0.059089  0.066089  0.125541 -0.042234   \n",
       "\n",
       "          kurt    sp.ent       sfm   ...    centroid   meanfun    minfun  \\\n",
       "35   -0.022713  0.106866  0.216255   ...   -0.100945 -0.123865 -0.094643   \n",
       "627  -0.024488  0.271365  0.362597   ...   -0.077168 -0.129024 -0.015679   \n",
       "1375 -0.024901  0.044442 -0.103720   ...    0.075031 -0.071623  0.055186   \n",
       "2425 -0.019957 -0.217464 -0.210421   ...    0.181834  0.045072  0.053981   \n",
       "446  -0.023494  0.186387  0.240967   ...   -0.010806 -0.173962 -0.106809   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  gender  \n",
       "35   -0.513695 -0.154699 -0.098732 -0.111527 -0.109554  0.046189     1.0  \n",
       "627   0.019616 -0.215011 -0.098732 -0.199089 -0.197179  0.034188     1.0  \n",
       "1375  0.114915 -0.059927 -0.064324 -0.019675 -0.018352 -0.076912     1.0  \n",
       "2425  0.105751  0.581402 -0.064324  0.292333  0.293880 -0.032648     0.0  \n",
       "446  -0.561536  0.052686 -0.047120  0.074678  0.075711  0.044632     1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also beneficial to split the data into training and testing data, so that we can verify whether logistic regression can accurately predict the gender of a voice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_train = pd.DataFrame()\n",
    "df_train = df_voice[:2100]\n",
    "df_test = df_voice[2100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we split the testing data to a column vector of gender and\n",
    "y_train = df_train[\"gender\"].as_matrix()\n",
    "X_train = df_train.drop(\"gender\",1).as_matrix()\n",
    "y_test = df_test[\"gender\"].as_matrix()\n",
    "X_test = df_test.drop(\"gender\",1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = y_train.transpose()\n",
    "X_train = X_train.transpose()\n",
    "X_train = np.append(np.ones((1,2100)), X_train, axis = 0)\n",
    "y_test = y_test.transpose()\n",
    "X_test = X_test.transpose()\n",
    "X_test= np.append(np.ones((1,1068)), X_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    result = 1.0/(1.0+np.exp(-x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(x,y,w):\n",
    "    item = np.dot(np.transpose(w),x)\n",
    "    result = y*log(sigmoid(item))+(1-y)*log(1.0-(sigmoid(item)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_plotter = []\n",
    "def stochGradDescent(outputVector,inputMatrix,learningSpeed):\n",
    "    #outputVector should be a binary column vector of classifications\n",
    "    # every column is a single trial, every row is a feature\n",
    "    a = learningSpeed\n",
    "    y = outputVector\n",
    "    X = inputMatrix\n",
    "    numberOfTrials = y.shape[0]\n",
    "    numberOfEstimators = X.shape[0]\n",
    "    prev_weight = np.ones(numberOfEstimators) #estimator vector (_t_heta)\n",
    "    weight = np.zeros(numberOfEstimators)\n",
    "    error = 10000.0\n",
    "    prev_training_cost = 1000.0\n",
    "    training_cost = 0 # This is what we're trying to maximize, the log likelihood\n",
    "    # add an additional loop to observe the training_cost\n",
    "    while ((prev_training_cost < training_cost) or (abs(prev_training_cost - training_cost) > 1e-10)):\n",
    "        training_cost = 0.0\n",
    "        while (np.linalg.norm(prev_weight-weight,ord=2) > 1e-6):\n",
    "            prev_weight = weight\n",
    "            # Randomly choose an integer\n",
    "            i = randint(1,2099)\n",
    "            grad = (y[i] - sigmoid(np.dot(np.transpose(prev_weight),X[:,i])))\n",
    "            weight = prev_weight + a * grad * X[:,i]\n",
    "            training_cost += log_likelihood(X[:,i],y[i],weight) \n",
    "            weight_plotter.append(np.linalg.norm(weight,ord=2))\n",
    "        prev_training_cost = training_cost\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.36397254e-01,   4.54430213e-01,   9.71622213e-01,\n",
       "        -4.31239524e-01,  -2.48662876e+00,   2.66592841e+00,\n",
       "         5.17129792e+00,  -1.39260180e+00,  -8.01885800e-01,\n",
       "         2.68968525e+00,  -2.45014710e+00,   1.26528210e+00,\n",
       "         4.54430213e-01,  -1.49776343e+01,   1.00181512e+00,\n",
       "        -8.48963305e-01,   1.50805198e-02,  -4.40295733e-01,\n",
       "        -1.14774326e-02,  -2.33249895e-03,  -8.92495772e-01])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = stochGradDescent(y_train,X_train,1.0/200.0)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(inputVector,estimatorVector):\n",
    "    t = estimatorVector\n",
    "    x = inputVector\n",
    "    confidence = sigmoid(np.dot(np.transpose(t) , x))\n",
    "    if confidence > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030 38 1068\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "total = 0\n",
    "for j in range(1068):\n",
    "    # print(predict(X_test[:,j],theta)), y_test[j]\n",
    "    if (y_test[j] == predict(X_test[:,j],theta)):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    total += 1\n",
    "print correct, wrong, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7bac69990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(len(weight_plotter)):\n",
    "    x.append(i)\n",
    "plt.plot(x,weight_plotter)\n",
    "plt.title(\"Convergence of weights\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"L2 norm of weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
